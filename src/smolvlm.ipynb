{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb16b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "Can you describe this image?\n",
      "Assistant: The image depicts a scene at sunset, likely in a park or a similar outdoor setting. The primary focus is on a person who appears to be playing a baseball bat or a similar outdoor activity. The person is standing on a grassy area, with a baseball bat or a similar object in their hand. The person is wearing a dark-colored shirt and shorts, and they are holding the bat or the object in their right hand.\n",
      "\n",
      "The background of the image is dominated by a building with a modern architectural style. The building has a flat roof and a few windows, and it appears to be a multi-story structure. The building is surrounded by trees and other greenery, suggesting that it is a park or a recreational area.\n",
      "\n",
      "In the foreground, there is a shadow of the person and the building. The shadow is elongated and dark, indicating that it is likely the sun is setting behind the building. The sun itself is not visible in the image, but its position and angle suggest that it is rising or setting.\n",
      "\n",
      "The sky is a gradient of colors, transitioning from a soft, warm tone at the top to a more intense, deep blue at the bottom. The sun is positioned slightly above the horizon, casting a warm glow over the scene.\n",
      "\n",
      "The overall mood of the image is peaceful and serene, with the setting suggesting a leisurely or recreational activity. The person's posture and the shadows suggest that they are either playing or watching a game of baseball.\n",
      "\n",
      "### Analysis and Description:\n",
      "1. **Setting**: The setting is a park or a recreational area, likely a park or a similar outdoor space.\n",
      "2. **Person**: The person is playing a baseball or a similar outdoor activity.\n",
      "3. **Building**: The building is modern, with a flat roof and a few windows.\n",
      "4. **Sunset**: The sun is setting, casting a warm glow over the scene.\n",
      "5. **Sky**: The sky is a gradient of colors, transitioning from a soft, warm tone at the top to a more intense, deep blue at the bottom.\n",
      "6. **Shadow**: The shadow of the person and the building is elongated and dark, indicating that it is likely the sun is rising or setting.\n",
      "\n",
      "### Answer to Potential Questions:\n",
      "1. **What is the person doing?**\n",
      "   - The person is playing a baseball or a similar outdoor activity.\n",
      "\n",
      "2. **What time of day is depicted in the\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "DEVICE = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load images\n",
    "image_path = \"/mnt/NAS-TVS872XT/dataset-lab/Kinetics400.frames/train/hitting baseball/AuoNAN7dyO8_000011_000021/000008.jpg\"\n",
    "image = [\n",
    "    Image.open(image_path)\n",
    "]\n",
    "\n",
    "# Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-256M-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-256M-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation=\"eager\"\n",
    ").to(DEVICE)\n",
    "\n",
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe this image?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(DEVICE)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "print(generated_texts[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minipro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
